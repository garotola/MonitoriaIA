{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:09.558249815Z",
     "start_time": "2023-11-21T18:24:08.709495603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importando Bibliotecas\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:09.563576512Z",
     "start_time": "2023-11-21T18:24:09.529900550Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "CATEGORIES = ['Avião', 'Automóvel','Passáro','Gato','Cervo','Cachorro', 'Sapo', 'Cavalo', 'Navio', 'Caminhão']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:48.663007213Z",
     "start_time": "2023-11-21T18:24:09.532210678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar-10-python.tar.gz to ./\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dados \n",
    "cifar10_train = CIFAR10(DATA_DIR, train=True, download=True)\n",
    "cifar10_test = CIFAR10(DATA_DIR, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:48.663617832Z",
     "start_time": "2023-11-21T18:24:33.722648538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 10000)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(cifar10_train), len(cifar10_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:48.973264694Z",
     "start_time": "2023-11-21T18:24:33.765906113Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as tt\n",
    "prep_transform = tt.Compose([tt.ToTensor(), tt.Normalize(\n",
    "    (0.4914, 0.4822, 0.4465),\n",
    "    (0.2470, 0.2435, 0.2616)\n",
    ")])\n",
    "tensor_train = CIFAR10(DATA_DIR, train=True, download=False, transform=prep_transform)\n",
    "tensor_test = CIFAR10(DATA_DIR, train=False, download=False, transform=prep_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.707387642Z",
     "start_time": "2023-11-21T18:24:34.986852830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 32, 32, 50000])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_train], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.707929538Z",
     "start_time": "2023-11-21T18:24:47.725672725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-1.2762e-06, -1.7074e-04,  1.1819e-04])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).mean(dim=1) # Média das Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.966923719Z",
     "start_time": "2023-11-21T18:24:47.818548842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0001, 0.9999, 1.0000])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.view(3, -1).std(dim=1) # Desvio Padrão das Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.967162296Z",
     "start_time": "2023-11-21T18:24:48.201993241Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(tensor_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(tensor_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.967327470Z",
     "start_time": "2023-11-21T18:24:48.225001839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testando o MLP para classificar imagem\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class MLPClassifier(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x) :\n",
    "        v = self.flatten(x)\n",
    "        return self.layers(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.967844223Z",
     "start_time": "2023-11-21T18:24:48.244543605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando na cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Rodando na {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.968120024Z",
     "start_time": "2023-11-21T18:24:48.318652003Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MLPClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:24:54.968290087Z",
     "start_time": "2023-11-21T18:24:48.365827371Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "lossfunc = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:25:43.956577465Z",
     "start_time": "2023-11-21T18:25:43.876031420Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, lossfunc, optimizer) :\n",
    "    model.train(True)\n",
    "    cumloss = 0.0\n",
    "    for imgs, labels in dataloader :\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        pred = model(imgs)\n",
    "        loss = lossfunc(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cumloss += loss.item()\n",
    "    return cumloss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, loss_func) : \n",
    "    model.eval()\n",
    "    cumloss = 0.0\n",
    "    with torch.no_grad() : \n",
    "        for imgs, labels in dataloader : \n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            pred = model(imgs)\n",
    "            loss = loss_func(pred, labels)\n",
    "            cumloss += loss.item()\n",
    "        return cumloss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:25:46.566267325Z",
     "start_time": "2023-11-21T18:25:46.553492447Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    fig = plt.figure(figsize=(13, 5))\n",
    "    ax = fig.gca()\n",
    "    for loss_name, loss_values in losses.items():  \n",
    "        ax.plot(loss_values, label=loss_name)\n",
    "    ax.legend(fontsize=\"16\")\n",
    "    ax.set_xlabel(\"Iteração\", fontsize=\"16\")\n",
    "    ax.set_ylabel(\"Perda\", fontsize=\"16\")\n",
    "    ax.set_title(\"Perdas vs Iterações\", fontsize=\"16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-21T18:25:47.307731298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Época][0] - Erro de Treinamento : 2.26055165477421 - Erro de Teste : 2.236305050029876\n",
      "[Época][10] - Erro de Treinamento : 1.822542947881362 - Erro de Teste : 1.8043669530540516\n",
      "[Época][20] - Erro de Treinamento : 1.624824050137454 - Erro de Teste : 1.6160045998870947\n",
      "[Época][30] - Erro de Treinamento : 1.5107640258186614 - Erro de Teste : 1.5263627539774416\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for t in range(epochs) :\n",
    "    train_loss = train(model, train_loader, lossfunc, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    test_loss = validate(model, test_loader, lossfunc)\n",
    "    test_losses.append(test_loss)\n",
    "    if(t % 10 == 0) :\n",
    "        print(f\"[Época][{t}] - Erro de Treinamento : {train_loss} - Erro de Teste : {test_loss}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:25:10.693045682Z",
     "start_time": "2023-11-21T18:25:10.690717676Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = {\"Perda no Treinamento : \" :  train_losses, \"Perda no teste : \" : test_losses}\n",
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T18:25:10.696985757Z"
    }
   },
   "outputs": [],
   "source": [
    "import sysconfig\n",
    "from PIL import Image\n",
    "img = Image.open('./Fusca.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T18:25:10.702013325Z"
    }
   },
   "outputs": [],
   "source": [
    "prep_transforms = tt.Compose([\n",
    "    tt.Resize((32,32)),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(\n",
    "    (0.4914, 0.4822, 0.4465),\n",
    "    (0.2470, 0.2435, 0.2616))\n",
    "    \n",
    "])\n",
    "\n",
    "img_tensor = prep_transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T18:25:10.707082727Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor.permute(1,2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T18:25:10.753783036Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = img_tensor.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:25:10.755765260Z",
     "start_time": "2023-11-21T18:25:10.753968533Z"
    }
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "output = model(batch)\n",
    "logits = torch.nn.functional.softmax(output, dim=1) * 100\n",
    "prob_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "for i, classname in enumerate(CATEGORIES):\n",
    "  prob = logits[0][i].item()\n",
    "  prob_dict[classname] = [prob]\n",
    "\n",
    "result = max(prob_dict.items(), key=operator.itemgetter(1))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
